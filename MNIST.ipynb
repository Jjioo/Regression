{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "ZBiuyDonaqr1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "     "
      ],
      "metadata": {
        "id": "Wvj-NVNpUhqx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwcVa1utUDGX",
        "outputId": "3e2e0a28-c4e5-4b6d-8814-8b4aecf9d060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "# Extract the feature matrix X and the target vector y\n",
        "X = mnist.data\n",
        "y = mnist.target\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_size = 0.8 # Training set size (80%)\n",
        "train_samples = int(len(X) * train_size)\n",
        "\n",
        "X_train = X[:train_samples]\n",
        "y_train = y[:train_samples]\n",
        "X_test = X[train_samples:]\n",
        "y_test = y[train_samples:]\n",
        "     "
      ],
      "metadata": {
        "id": "6cvrD67KUmH6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {'n_neighbors': range(1, 21)}  # Range of K values to try\n",
        "\n",
        "# Create the KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(knn, param_grid, cv=5)  # Adjust the number of folds (cv) as desired\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best K value\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "print(\"Best K:\", best_k)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "WTOCVPBfUpoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the KNN classifier\n",
        "k = 8 # Number of neighbors\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "id": "l9Ov1VujUylW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3D scatter plot for three features\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Extract the values for plotting\n",
        "x1 = X_test.iloc[:, 0]\n",
        "x2 = X_test.iloc[:, 1]\n",
        "x3 = X_test.iloc[:, 2]\n",
        "\n",
        "\n",
        "# Convert y_pred to integer type\n",
        "y_pred_int = y_pred.astype(int)\n",
        "\n",
        "# Plot the data points\n",
        "ax.scatter(x1, x2, x3, c=y_pred_int, cmap='viridis')\n",
        "\n",
        "ax.set_xlabel(\"Feature 1\")\n",
        "ax.set_ylabel(\"Feature 2\")\n",
        "ax.set_zlabel(\"Feature 3\")\n",
        "ax.set_title(\"KNN Classification (3D)\")\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-7fxcTXLVCV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}